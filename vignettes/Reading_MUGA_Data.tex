\documentclass{article}
\usepackage{fullpage}
\usepackage{hyperref}
\marginparwidth 0pt
\oddsidemargin 0pt
\evensidemargin 0pt
\topmargin 0pt
\textwidth 16cm
\textheight 21cm

\usepackage{Sweave}

\begin{document}

\input{Reading_MUGA_Data-concordance}

\title{Reading Raw MUGA and MegaMUGA Data}
\author{Daniel M. Gatti}
\date{03 October 2013}
\maketitle

\section{Extracting Genotypes and Intensities}

This vignette explains how to read in the raw MUGA and MegaMUGA data as it is received from \href{http://www.neogen.com/Agrigenomics/ResearchDevelop.html}{GeneSeek} (Lincoln, NE). When genotyping \href{http://jaxmice.jax.org/strain/009376.html}{Diversity Outbred} (DO) mice, GeneSeek provides six files:

\begin{enumerate}
  \item{\verb|*_|DNAReport.csv: Quality metrics per sample containing allele call rates and frequencies.}
  \item{\verb|*_|FinalReport.txt: The main data file containing allele calls and intensities.}
  \item{\verb|*_|LocusSummary.csv: Quality metrics for each marker.}
  \item{\verb|*_|LocusXDNA.csv: Combined sample and marker quality report.}
  \item{Sample\verb|_|map.txt: A list of sample IDs and plate locations.}
  \item{SNP\verb|_|Map.txt: A list of the SNPs assayed with genomic locations.}
\end{enumerate}

The two files required by DOQTL are \verb|*_|FinalReport.txt and Sample\verb|_|map.txt. They are expected to be in the same directory. Each data set from GeneSeek should also be in a separate directory. 

\vspace{5 mm}

Below, we load in example data and write it out to directories similar to what GeneSeek produces.

\begin{Schunk}
\begin{Sinput}
> library(DOQTL)
\end{Sinput}
\begin{Soutput}
R/QTLRel is loaded
\end{Soutput}
\begin{Sinput}
> wd = tempdir()
> data.dirs = paste(wd, "/DataSet", 1:2, sep = "")
> dir.create(data.dirs[1])
> dir.create(data.dirs[2])
> library(MUGAExampleData)
> data(FinalReport1)
> data(Samples1)
> write(FinalReport1, file = paste(data.dirs[1], "DataSet1_FinalReport.txt", 
+                                  sep = "/"))
> write(Samples1, file = paste(data.dirs[1], "Sample_Map.txt", sep = "/"))
> data(FinalReport2)
> data(Samples2)
> write(FinalReport2, file = paste(data.dirs[2], "DataSet2_FinalReport.txt",
+                                 sep = "/"))
> write(Samples2, file = paste(data.dirs[2], "Sample_Map.txt", sep = "/"))
\end{Sinput}
\end{Schunk}

The \verb|*_|FinalReport.txt files are tab delimited files that contain 11 columns.

\begin{enumerate}
  \item{SNP Name: marker ID}
  \item{Sample ID: sample ID}
  \item{Allele1 - Forward: allele call for one DNA strand}
  \item{Allele2 - Forward: allele call for the other DNA strand}
  \item{X: normalized X intensity}
  \item{Y: normalized X intensity}
  \item{GC Score: uncertain, ranges from 0 to 1, with a skew toward 1}
  \item{Theta: X and Y intensity transfomred to $\theta$ }
  \item{X Raw: raw X intensity}
  \item{Y Raw: raw Y intensity}
  \item{R: X and Y intensity transfomred to $\rho$}
\end{enumerate}

\begin{Schunk}
\begin{Sinput}
> read.delim(paste(data.dirs[1], "DataSet1_FinalReport.txt", 
+            sep = "/"), nrows = 6 ,skip = 9)
\end{Sinput}
\begin{Soutput}
           SNP.Name Sample.ID Allele1...Forward Allele2...Forward     X     Y
1 backupJAX00000484       F01                 A                 G 0.548 0.546
2 backupJAX00003592       F01                 G                 G 0.007 1.152
3 backupJAX00004293       F01                 T                 C 0.557 0.396
4 backupJAX00005508       F01                 G                 G 0.019 0.814
5 backupJAX00012065       F01                 T                 G 1.055 0.816
6 backupJAX00012423       F01                 G                 G 0.001 0.633
  GC.Score Theta X.Raw Y.Raw     R
1   0.6971 0.499  7415  5846 1.094
2   0.8788 0.996  1020 11655 1.158
3   0.7054 0.394  7497  4401 0.953
4   0.8860 0.985  1127  8385 0.833
5   0.7188 0.419 13503  8518 1.871
6   0.9637 0.999   888  6639 0.634
\end{Soutput}
\end{Schunk}

Each sample is listed sequentially. Note that the markers are not in genomic order in this file.

\vspace{5 mm}

The Sample\verb|_|Map.txt files contain a listing of the sample IDs and plate locations for each sample.

\begin{Schunk}
\begin{Sinput}
> read.delim(paste(data.dirs[1], "Sample_Map.txt", sep = "/"), nrows = 6)
\end{Sinput}
\begin{Soutput}
  Index Name       ID  Gender  Plate Well Group Parent1 Parent2 Replicate
1     1  F01 9376-F01 Unknown P02723  A01    NA      NA      NA        NA
2     2  F02 9376-F02 Unknown P02723  A02    NA      NA      NA        NA
3     3  F03 9376-F03 Unknown P02723  A03    NA      NA      NA        NA
4     4  F04 9376-F04 Unknown P02723  A04    NA      NA      NA        NA
5     5  F05 9376-F05 Unknown P02723  A05    NA      NA      NA        NA
6     6  F06 9376-F06 Unknown P02723  A06    NA      NA      NA        NA
    SentrixPosition
1 5532807102_R01C01
2 5532807102_R03C01
3 5532807102_R05C01
4 5532807102_R07C01
5 5532807102_R09C01
6 5532807102_R11C01
\end{Soutput}
\end{Schunk}

In practice, you will have one or more directories with genotyping results from GeneSeek. The genotype, X and Y intensity data can be extracted from these directories using the function \texttt{extract.raw.data()}. Place the path to the data directories in the \texttt{in path} argument, the output path in \texttt{out path} and specify whether the array is \texttt{muga} or \texttt{megamuga} in the \texttt{array} argument.

\begin{Schunk}
\begin{Sinput}
> extract.raw.data(in.path = data.dirs, out.path = wd, array = "muga")
\end{Sinput}
\end{Schunk}

This will create x.txt, y.txt, geno.txt and call.rate.batch.txt files in the ouput directory.

\begin{Schunk}
\begin{Sinput}
> list.files(path = wd, pattern = "txt$")
\end{Sinput}
\begin{Soutput}
[1] "call.rate.batch.txt" "geno.txt"            "x.txt"              
[4] "y.txt"              
\end{Soutput}
\end{Schunk}

Optionally, you may filter out samples with low allele call rates. Samples with call rates below 90\% 
often produce poor genome reconstructions. The function removes samples with call rates below the
threshold (default = 0.9), writes out the x.filt.txt, y.filt.txt and geno.filt.txt files and returns
the samples that were removed.

\begin{Schunk}
\begin{Sinput}
> removed = filter.samples(path = wd)
\end{Sinput}
\end{Schunk}
\begin{Schunk}
\begin{Sinput}
> removed
\end{Sinput}
\begin{Soutput}
    sample call.rate
37     M12 0.4146931
38     M13 0.3863000
115    F69 0.8506494
                                                           batch
37  C:\\Users\\dgatti\\AppData\\Local\\Temp\\RtmpGCRbyD/DataSet1
38  C:\\Users\\dgatti\\AppData\\Local\\Temp\\RtmpGCRbyD/DataSet1
115 C:\\Users\\dgatti\\AppData\\Local\\Temp\\RtmpGCRbyD/DataSet2
\end{Soutput}
\end{Schunk}

Three samples had call rates below 0.9.

\vspace{5 mm}

Finally, you may perform batch normalization on the intensity files. Currently, this simply subtracts the median intensity from each batch. Future improvements may be made to these methods. You must provide the SNP locations in the \texttt{snps} argument. We obtain these from the \href{ftp://ftp.jax.org/MUGA/}{JAX FTP site}.

\begin{Schunk}
\begin{Sinput}
> load(url("ftp://ftp.jax.org/MUGA/muga_snps.Rdata"))
> batch.normalize(path = wd, snps = muga_snps)
\end{Sinput}
\end{Schunk}

This will write out the files x.filt.norm.txt and  y.filt.norm.txt.  You may then use these as input into DOQTL's genome reconstruction pipeline.

\end{document}
